---
title: "Training a Tabnet model from missing-values dataset"
author: "Christophe Regouby"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{pretrain from dataset with missing-values}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = TRUE
)
```

# Motivation

Real-life training dataset usually contains missing data. The vast majority of deep-learning networks do not handle missing data and thus either stop or crash when values are missing in the predictors.

But Tabnet use a masking mechanism that can be adapted to cover the missing data in the training set.

As we enter the world of missing-data, we have to question the type of missing-data we deal with. We could have missing data at random (MAR), like for example some transmission errors on a sensor data dataset, or missing not at random (MNAR) when some interactions exists between the missing data and other predictors values for the same sample. The later is a more complex topic to cover, and we will try to investiate it here through the `ames` dataset.

# Missing-data dataset creation

## Ames missings understanding

The `ames` dataset from  `{modeldata}`  contains a lot of null values that the human analysis clearly interprete as a implicit missing object described by that value. We have for example pool surface of 0 square meters means "no pool", basement surface of 0 square meters means "no basement", ...A lot of them can be detected visually by inspecting the distribution of the values like for the `Masonry veneer area` predictor :
```{r}
library(tidymodels, warn.conflicts = FALSE)
library(tabnet)
data("ames", package = "modeldata")
qplot(ames$Mas_Vnr_Area)
```
![ames variable Mas_Vnr_Area histogram showing high occurence of value zero](ames_mas_vnr_hist.png)
We know that it will be extremely difficult for a model to capture an internal representation of such distribution, and thus we want to avoid the zero values to penalize the model internal representation.

## While keeping some room for freedom

A lot of those variables come as a pair in the `ames` dataset, one for the qualitative aspect,  the other for the quantitative aspect. We have for exemple `Pool_QC` for pool condition, that has a "no_pool" level with `Pool_Area=0` in that case.  
As human, we have the intuition that knowing if a pool is present is important for the modelling task. So we want the model to get an internal representation of the implicit `has_pool=FALSE` without having it explicit in the dataset. In order to do so, we have to let the model some freedom to infer the "no_pool" state and thus we should not mutate both variables in the pair `Pool_Area=NA` and `Pool_QC=NA` at the same time.  


## Ames with missing data

Let's turn those missing objects data explicitely into `NAs` in an new `ames_missing` dataset :

A quick and dirty way to achieve this on numerical predictors is to `na_if()` zeros on any column which name is related to surface and area.  
Then, according to the keep room for freedom rule, do it carefully on the matching categorical predictors

```{r}
col_with_zero_as_na <- ames %>% 
  select(where(is.numeric)) %>% 
  select(matches("_SF|Area|Misc_Val|[Pp]orch$")) %>% 
  summarise_each(min) %>% 
  select_if(~.x==0) %>% 
  names()
ames_missing <- ames %>% mutate_at(col_with_zero_as_na, na_if, 0) %>% 
  mutate_at("Alley", na_if, "No_Alley_Access") %>% 
  mutate_at("Fence", na_if, "No_Fence") %>% 
  mutate_at(c("Garage_Cond", "Garage_Finish"), na_if, "No_Garage") %>% 
  mutate_at(c("Bsmt_Exposure", "BsmtFin_Type_1", "BsmtFin_Type_2"), na_if, "No_Basement")
visdat::vis_miss(ames_missing)
```
![ames missing values visualisation showing few variables with more than 90% missingness with a global 13% missing](vis_miss_ames.png)

We can see here that variable are not missing at random, and thus we can expect the model to capture the missingness relation during the pretraining phase.

Note: A better way to achieve proper value mutation to explicit NAs would be to also check if the qualitative column in the pair refers to `none` or to zero occurence of the equipment. But this is beyond the scope of this vignette.

# Model pretraining

Let's pretrain one model for each of those dataset, and analyse variable importance that emerge after the unsupervised representation learning step:   

## Variable importance with raw `ames` dataset

```{r}
ames_rec <- recipe(Sale_Price ~ ., data=ames) %>% 
  step_normalize(all_numeric())

cat_emb_dim <- map_dbl(ames %>% select_if(is.factor), ~log2(nlevels(.x)) %>% round)

ames_fit <- tabnet_pretrain(ames_rec, data=ames,  epoch=50, cat_emb_dim = cat_emb_dim,
                            valid_split = 0.2, verbose=TRUE, batch=2930, 
                            early_stopping_patience = 3L, early_stopping_tolerance = 0.005)
autoplot(ames_fit)
```

```
[Epoch 001] Loss: 71.368286 Valid loss: 13.013237
[Epoch 002] Loss: 44.926559 Valid loss: 10.259305
[Epoch 003] Loss: 32.995518 Valid loss: 8.719707
[Epoch 004] Loss: 24.650784 Valid loss: 7.821852
[Epoch 005] Loss: 19.996607 Valid loss: 7.105954
[Epoch 006] Loss: 16.715664 Valid loss: 6.449599
...
[Epoch 047] Loss: 8.792793 Valid loss: 4.818432
[Epoch 048] Loss: 8.997622 Valid loss: 4.869482
[Epoch 049] Loss: 8.352752 Valid loss: 4.914999
[Epoch 050] Loss: 8.924073 Valid loss: 4.946170
```

![ames_fit model training diagnostic plot](ames_pretrain.png)

```{r}
vip::vip(ames_fit)
```
![ames_fit model variable importance plot](ames_pretrain_vip.png)

Training loss evolution is almost correct and we get `Alley` and `Pool_QC` variables in the top ten important variables according to the pretrained model. Those two variables have been screened as having a very important missing rate.

## Variable importance with `ames_missing` dataset

Let's pretrain a new model with the same hyperparameter, but now using the `ames_missing` dataset.  
In order to compensate the 13% missingness already present in the `ames_missing` dataset, we adjust the `pretraining_ratio` parameter to `0.5 - 0.13 = 0.37`

```{r}
ames_missing_rec <- recipe(Sale_Price ~ ., data=ames_missing) %>% 
  step_normalize(all_numeric())
ames_missing_fit <- tabnet_pretrain(ames_missing_rec, data=ames_missing, epoch=50, 
                                    cat_emb_dim = cat_emb_dim,
                                    valid_split = 0.2, verbose=TRUE, batch=2930, 
                                    pretraining_ratio=0.37, 
                                    early_stopping_patience = 3L, early_stopping_tolerance = 0.005)
autoplot(ames_missing_fit)
vip::vip(ames_missing_fit)
```
```
[Epoch 001] Loss: 41.925888 Valid loss: 11.546161
[Epoch 002] Loss: 32.214478 Valid loss: 10.309987
[Epoch 003] Loss: 24.262951 Valid loss: 9.479233
[Epoch 004] Loss: 19.042051 Valid loss: 8.434237
[Epoch 005] Loss: 15.512108 Valid loss: 7.437159
[Epoch 006] Loss: 12.279278 Valid loss: 6.486411
[Epoch 007] Loss: 10.196947 Valid loss: 5.815371
[Epoch 008] Loss: 9.259965 Valid loss: 5.111839
...
[Epoch 045] Loss: 6.641933 Valid loss: 4.190426
[Epoch 046] Loss: 6.781425 Valid loss: 4.186747
[Epoch 047] Loss: 6.599716 Valid loss: 4.178854
[Epoch 048] Loss: 6.766137 Valid loss: 4.275692
[Epoch 049] Loss: 7.051480 Valid loss: 4.244986
[Epoch 050] Loss: 6.723494 Valid loss: 4.215664

```
![ames_missing_fit model training diagnostic plot](ames_missing_pretrain.png)
![ames_missing_fit model variable importance plot](ames_missing_pretrain_vip.png)

The model is slightly overfitting here, but we can see here no variables with high missingness is present in the top 10 important variables. This seems to be a good sign of the model having captured proper interactions between variables.

